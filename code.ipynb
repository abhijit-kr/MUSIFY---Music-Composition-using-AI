{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import LSTM,Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Sequential,Model,load_model \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and Parsing the Midi File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "  3%|▎         | 1/29 [00:45<21:25, 45.90s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 14%|█▍        | 4/29 [01:59<11:29, 27.58s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 8/29 [04:31<13:07, 37.52s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 41%|████▏     | 12/29 [05:25<05:17, 18.68s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 45%|████▍     | 13/29 [06:23<08:13, 30.82s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 59%|█████▊    | 17/29 [07:57<05:23, 27.00s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 66%|██████▌   | 19/29 [08:38<03:57, 23.79s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1996 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 20/29 [09:03<03:36, 24.09s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      " 97%|█████████▋| 28/29 [10:31<00:13, 13.75s/it]c:\\Users\\abhik\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\music21\\midi\\translate.py:883: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "100%|██████████| 29/29 [10:54<00:00, 22.56s/it]\n",
      "C:\\Users\\abhik\\AppData\\Local\\Temp\\ipykernel_24472\\1958659278.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)])\n"
     ]
    }
   ],
   "source": [
    "def read_files(file):\n",
    "  notes=[]\n",
    "  notes_to_parse=None\n",
    "  #parse the midi file\n",
    "  midi=converter.parse(file)\n",
    "  #seperate all instruments from the file\n",
    "  instrmt=instrument.partitionByInstrument(midi)\n",
    "\n",
    "  for part in instrmt.parts:\n",
    "    #fetch data only of Piano instrument\n",
    "    if 'Piano' in str(part):\n",
    "      notes_to_parse=part.recurse()\n",
    "\n",
    "      #iterate over all the parts of sub stream elements\n",
    "      #check if element's type is Note or chord\n",
    "      #if it is chord split them into notes\n",
    "      for element in notes_to_parse:\n",
    "        if type(element)==note.Note:\n",
    "          notes.append(str(element.pitch))\n",
    "        elif type(element)==chord.Chord:\n",
    "          notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "  #return the list of notes\n",
    "  return notes\n",
    "\n",
    "#retrieve paths recursively from inside the directories/files\n",
    "file_path=[\"schubert\"]\n",
    "all_files=glob.glob('All Midi Files/'+file_path[0]+'/*.mid',recursive=True)\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Notes: 345\n",
      "\n",
      "Frequency notes\n",
      "30 : 204\n",
      "50 : 182\n",
      "70 : 163\n",
      "90 : 153\n"
     ]
    }
   ],
   "source": [
    "#unique notes\n",
    "notess = sum(notes_array,[]) \n",
    "unique_notes = list(set(notess))\n",
    "print(\"Unique Notes:\",len(unique_notes))\n",
    "\n",
    "#notes with their frequency\n",
    "freq=dict(map(lambda x: (x,notess.count(x)),unique_notes))\n",
    "\n",
    "#get the threshold frequency\n",
    "print(\"\\nFrequency notes\")\n",
    "for i in range(30,100,20):\n",
    "  print(i,\":\",len(list(filter(lambda x:x[1]>=i,freq.items()))))\n",
    "\n",
    "#filter notes greater than threshold i.e. 50\n",
    "freq_notes=dict(filter(lambda x:x[1]>=50,freq.items()))\n",
    "\n",
    "#create new notes using the frequent notes\n",
    "new_notes=[[i for i in j if i in freq_notes] for j in notes_array]\n",
    "\n",
    "#dictionary having key as note index and value as note\n",
    "ind2note=dict(enumerate(freq_notes))\n",
    "\n",
    "#dictionary having key as note and value as note index\n",
    "note2ind=dict(map(reversed,ind2note.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input and Output Sequence for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestep\n",
    "timesteps=50\n",
    "\n",
    "#store values of input and output\n",
    "x=[] ; y=[]\n",
    "\n",
    "for i in new_notes:\n",
    "  for j in range(0,len(i)-timesteps):\n",
    "    #input will be the current index + timestep\n",
    "    #output will be the next index after timestep\n",
    "    inp=i[j:j+timesteps] ; out=i[j+timesteps]\n",
    "\n",
    "    #append the index value of respective notes \n",
    "    x.append(list(map(lambda x:note2ind[x],inp)))\n",
    "    y.append(note2ind[out])\n",
    "\n",
    "x_new=np.array(x) \n",
    "y_new=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape input and output for the model\n",
    "x_new = np.reshape(x_new,(len(x_new),timesteps,1))\n",
    "y_new = np.reshape(y_new,(-1,1))\n",
    "\n",
    "#split the input and value into training and testing sets\n",
    "#80% for training and 20% for testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 256)           264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 182)               46774     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 902,070\n",
      "Trainable params: 902,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model = Sequential()\n",
    "#create two stacked LSTM layer with the latent dimension of 256\n",
    "model.add(LSTM(256,return_sequences=True,input_shape=(x_new.shape[1],x_new.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "#fully connected layer for the output with softmax activation\n",
    "model.add(Dense(len(note2ind),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "489/489 [==============================] - 371s 742ms/step - loss: 4.7440 - accuracy: 0.0297 - val_loss: 4.6185 - val_accuracy: 0.0385\n",
      "Epoch 2/80\n",
      "489/489 [==============================] - 341s 698ms/step - loss: 4.5550 - accuracy: 0.0495 - val_loss: 4.4916 - val_accuracy: 0.0549\n",
      "Epoch 3/80\n",
      "489/489 [==============================] - 327s 669ms/step - loss: 4.3846 - accuracy: 0.0693 - val_loss: 4.3362 - val_accuracy: 0.0738\n",
      "Epoch 4/80\n",
      "489/489 [==============================] - 325s 665ms/step - loss: 4.2001 - accuracy: 0.0901 - val_loss: 4.1735 - val_accuracy: 0.0940\n",
      "Epoch 5/80\n",
      "489/489 [==============================] - 324s 663ms/step - loss: 4.0116 - accuracy: 0.1133 - val_loss: 3.9865 - val_accuracy: 0.1147\n",
      "Epoch 6/80\n",
      "489/489 [==============================] - 328s 671ms/step - loss: 3.8251 - accuracy: 0.1359 - val_loss: 3.8590 - val_accuracy: 0.1305\n",
      "Epoch 7/80\n",
      "489/489 [==============================] - 332s 680ms/step - loss: 3.6530 - accuracy: 0.1557 - val_loss: 3.7469 - val_accuracy: 0.1492\n",
      "Epoch 8/80\n",
      "489/489 [==============================] - 323s 660ms/step - loss: 3.4946 - accuracy: 0.1760 - val_loss: 3.6417 - val_accuracy: 0.1589\n",
      "Epoch 9/80\n",
      "489/489 [==============================] - 317s 647ms/step - loss: 3.3543 - accuracy: 0.1944 - val_loss: 3.5708 - val_accuracy: 0.1705\n",
      "Epoch 10/80\n",
      "489/489 [==============================] - 286s 586ms/step - loss: 3.2339 - accuracy: 0.2133 - val_loss: 3.5121 - val_accuracy: 0.1792\n",
      "Epoch 11/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 3.1185 - accuracy: 0.2323 - val_loss: 3.4786 - val_accuracy: 0.1838\n",
      "Epoch 12/80\n",
      "489/489 [==============================] - 280s 572ms/step - loss: 3.0218 - accuracy: 0.2448 - val_loss: 3.4539 - val_accuracy: 0.1944\n",
      "Epoch 13/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 2.9417 - accuracy: 0.2568 - val_loss: 3.4226 - val_accuracy: 0.1956\n",
      "Epoch 14/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 2.8575 - accuracy: 0.2713 - val_loss: 3.3770 - val_accuracy: 0.2065\n",
      "Epoch 15/80\n",
      "489/489 [==============================] - 294s 600ms/step - loss: 2.7727 - accuracy: 0.2852 - val_loss: 3.3559 - val_accuracy: 0.2099\n",
      "Epoch 16/80\n",
      "489/489 [==============================] - 285s 583ms/step - loss: 2.7048 - accuracy: 0.2972 - val_loss: 3.3380 - val_accuracy: 0.2166\n",
      "Epoch 17/80\n",
      "489/489 [==============================] - 281s 575ms/step - loss: 2.6455 - accuracy: 0.3079 - val_loss: 3.3332 - val_accuracy: 0.2151\n",
      "Epoch 18/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 2.5795 - accuracy: 0.3175 - val_loss: 3.3250 - val_accuracy: 0.2196\n",
      "Epoch 19/80\n",
      "489/489 [==============================] - 284s 580ms/step - loss: 2.5234 - accuracy: 0.3299 - val_loss: 3.3001 - val_accuracy: 0.2256\n",
      "Epoch 20/80\n",
      "489/489 [==============================] - 283s 580ms/step - loss: 2.4718 - accuracy: 0.3403 - val_loss: 3.3131 - val_accuracy: 0.2267\n",
      "Epoch 21/80\n",
      "489/489 [==============================] - 283s 579ms/step - loss: 2.4160 - accuracy: 0.3507 - val_loss: 3.3247 - val_accuracy: 0.2312\n",
      "Epoch 22/80\n",
      "489/489 [==============================] - 279s 571ms/step - loss: 2.3697 - accuracy: 0.3598 - val_loss: 3.3272 - val_accuracy: 0.2323\n",
      "Epoch 23/80\n",
      "489/489 [==============================] - 282s 577ms/step - loss: 2.3214 - accuracy: 0.3700 - val_loss: 3.3147 - val_accuracy: 0.2371\n",
      "Epoch 24/80\n",
      "489/489 [==============================] - 295s 603ms/step - loss: 2.2771 - accuracy: 0.3764 - val_loss: 3.3159 - val_accuracy: 0.2411\n",
      "Epoch 25/80\n",
      "489/489 [==============================] - 277s 566ms/step - loss: 2.2441 - accuracy: 0.3845 - val_loss: 3.3340 - val_accuracy: 0.2437\n",
      "Epoch 26/80\n",
      "489/489 [==============================] - 277s 566ms/step - loss: 2.1949 - accuracy: 0.3947 - val_loss: 3.3296 - val_accuracy: 0.2457\n",
      "Epoch 27/80\n",
      "489/489 [==============================] - 274s 561ms/step - loss: 2.1642 - accuracy: 0.4010 - val_loss: 3.3347 - val_accuracy: 0.2486\n",
      "Epoch 28/80\n",
      "489/489 [==============================] - 280s 574ms/step - loss: 2.1350 - accuracy: 0.4058 - val_loss: 3.3296 - val_accuracy: 0.2475\n",
      "Epoch 29/80\n",
      "489/489 [==============================] - 277s 566ms/step - loss: 2.0900 - accuracy: 0.4144 - val_loss: 3.3506 - val_accuracy: 0.2506\n",
      "Epoch 30/80\n",
      "489/489 [==============================] - 279s 571ms/step - loss: 2.0553 - accuracy: 0.4245 - val_loss: 3.3533 - val_accuracy: 0.2510\n",
      "Epoch 31/80\n",
      "489/489 [==============================] - 278s 568ms/step - loss: 2.0253 - accuracy: 0.4323 - val_loss: 3.3685 - val_accuracy: 0.2522\n",
      "Epoch 32/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 1.9904 - accuracy: 0.4356 - val_loss: 3.3853 - val_accuracy: 0.2528\n",
      "Epoch 33/80\n",
      "489/489 [==============================] - 280s 573ms/step - loss: 1.9799 - accuracy: 0.4398 - val_loss: 3.3642 - val_accuracy: 0.2581\n",
      "Epoch 34/80\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 1.9327 - accuracy: 0.4506 - val_loss: 3.3757 - val_accuracy: 0.2633\n",
      "Epoch 35/80\n",
      "489/489 [==============================] - 278s 567ms/step - loss: 1.9121 - accuracy: 0.4554 - val_loss: 3.3972 - val_accuracy: 0.2653\n",
      "Epoch 36/80\n",
      "489/489 [==============================] - 279s 571ms/step - loss: 1.8890 - accuracy: 0.4610 - val_loss: 3.4144 - val_accuracy: 0.2640\n",
      "Epoch 37/80\n",
      "489/489 [==============================] - 277s 566ms/step - loss: 1.8672 - accuracy: 0.4651 - val_loss: 3.4190 - val_accuracy: 0.2669\n",
      "Epoch 38/80\n",
      "489/489 [==============================] - 283s 579ms/step - loss: 1.8328 - accuracy: 0.4747 - val_loss: 3.4370 - val_accuracy: 0.2660\n",
      "Epoch 39/80\n",
      "489/489 [==============================] - 279s 570ms/step - loss: 1.8211 - accuracy: 0.4764 - val_loss: 3.4333 - val_accuracy: 0.2720\n",
      "Epoch 40/80\n",
      "489/489 [==============================] - 280s 574ms/step - loss: 1.7885 - accuracy: 0.4864 - val_loss: 3.4719 - val_accuracy: 0.2686\n",
      "Epoch 41/80\n",
      "489/489 [==============================] - 282s 577ms/step - loss: 1.7732 - accuracy: 0.4865 - val_loss: 3.4661 - val_accuracy: 0.2702\n",
      "Epoch 42/80\n",
      "489/489 [==============================] - 279s 570ms/step - loss: 1.7671 - accuracy: 0.4894 - val_loss: 3.4628 - val_accuracy: 0.2738\n",
      "Epoch 43/80\n",
      "489/489 [==============================] - 283s 579ms/step - loss: 1.7380 - accuracy: 0.4983 - val_loss: 3.4886 - val_accuracy: 0.2720\n",
      "Epoch 44/80\n",
      "489/489 [==============================] - 282s 577ms/step - loss: 1.7155 - accuracy: 0.4993 - val_loss: 3.5013 - val_accuracy: 0.2748\n",
      "Epoch 45/80\n",
      "489/489 [==============================] - 281s 574ms/step - loss: 1.7016 - accuracy: 0.5050 - val_loss: 3.5005 - val_accuracy: 0.2784\n",
      "Epoch 46/80\n",
      "489/489 [==============================] - 282s 578ms/step - loss: 1.6689 - accuracy: 0.5128 - val_loss: 3.5320 - val_accuracy: 0.2752\n",
      "Epoch 47/80\n",
      "489/489 [==============================] - 282s 576ms/step - loss: 1.6558 - accuracy: 0.5162 - val_loss: 3.5346 - val_accuracy: 0.2774\n",
      "Epoch 48/80\n",
      "489/489 [==============================] - 283s 579ms/step - loss: 1.6422 - accuracy: 0.5178 - val_loss: 3.5603 - val_accuracy: 0.2797\n",
      "Epoch 49/80\n",
      "489/489 [==============================] - 284s 582ms/step - loss: 1.6242 - accuracy: 0.5234 - val_loss: 3.5548 - val_accuracy: 0.2807\n",
      "Epoch 50/80\n",
      "489/489 [==============================] - 284s 581ms/step - loss: 1.6124 - accuracy: 0.5248 - val_loss: 3.5644 - val_accuracy: 0.2824\n",
      "Epoch 51/80\n",
      "489/489 [==============================] - 284s 582ms/step - loss: 1.5983 - accuracy: 0.5303 - val_loss: 3.5544 - val_accuracy: 0.2849\n",
      "Epoch 52/80\n",
      "489/489 [==============================] - 287s 587ms/step - loss: 1.5750 - accuracy: 0.5359 - val_loss: 3.5852 - val_accuracy: 0.2840\n",
      "Epoch 53/80\n",
      "489/489 [==============================] - 288s 589ms/step - loss: 1.5643 - accuracy: 0.5365 - val_loss: 3.5971 - val_accuracy: 0.2856\n",
      "Epoch 54/80\n",
      "489/489 [==============================] - 286s 585ms/step - loss: 1.5626 - accuracy: 0.5374 - val_loss: 3.5835 - val_accuracy: 0.2924\n",
      "Epoch 55/80\n",
      "489/489 [==============================] - 289s 592ms/step - loss: 1.5452 - accuracy: 0.5421 - val_loss: 3.6111 - val_accuracy: 0.2896\n",
      "Epoch 56/80\n",
      "489/489 [==============================] - 286s 586ms/step - loss: 1.5364 - accuracy: 0.5475 - val_loss: 3.5982 - val_accuracy: 0.2911\n",
      "Epoch 57/80\n",
      "489/489 [==============================] - 287s 588ms/step - loss: 1.5137 - accuracy: 0.5505 - val_loss: 3.6305 - val_accuracy: 0.2931\n",
      "Epoch 58/80\n",
      "489/489 [==============================] - 287s 587ms/step - loss: 1.5071 - accuracy: 0.5519 - val_loss: 3.6401 - val_accuracy: 0.2908\n",
      "Epoch 59/80\n",
      "489/489 [==============================] - 288s 589ms/step - loss: 1.4943 - accuracy: 0.5553 - val_loss: 3.6644 - val_accuracy: 0.2902\n",
      "Epoch 60/80\n",
      "489/489 [==============================] - 289s 592ms/step - loss: 1.4815 - accuracy: 0.5605 - val_loss: 3.6416 - val_accuracy: 0.2927\n",
      "Epoch 61/80\n",
      "489/489 [==============================] - 286s 585ms/step - loss: 1.4736 - accuracy: 0.5606 - val_loss: 3.6855 - val_accuracy: 0.2905\n",
      "Epoch 62/80\n",
      "489/489 [==============================] - 290s 594ms/step - loss: 1.4545 - accuracy: 0.5635 - val_loss: 3.7256 - val_accuracy: 0.2914\n",
      "Epoch 63/80\n",
      "489/489 [==============================] - 292s 596ms/step - loss: 1.4479 - accuracy: 0.5672 - val_loss: 3.6973 - val_accuracy: 0.2925\n",
      "Epoch 64/80\n",
      "489/489 [==============================] - 288s 589ms/step - loss: 1.4341 - accuracy: 0.5705 - val_loss: 3.7024 - val_accuracy: 0.2914\n",
      "Epoch 65/80\n",
      "489/489 [==============================] - 291s 596ms/step - loss: 1.4332 - accuracy: 0.5712 - val_loss: 3.7242 - val_accuracy: 0.2977\n",
      "Epoch 66/80\n",
      "489/489 [==============================] - 290s 592ms/step - loss: 1.4252 - accuracy: 0.5736 - val_loss: 3.7238 - val_accuracy: 0.2970\n",
      "Epoch 67/80\n",
      "489/489 [==============================] - 289s 591ms/step - loss: 1.4137 - accuracy: 0.5782 - val_loss: 3.7200 - val_accuracy: 0.2972\n",
      "Epoch 68/80\n",
      "489/489 [==============================] - 289s 592ms/step - loss: 1.4080 - accuracy: 0.5790 - val_loss: 3.7364 - val_accuracy: 0.3007\n",
      "Epoch 69/80\n",
      "489/489 [==============================] - 288s 590ms/step - loss: 1.3974 - accuracy: 0.5810 - val_loss: 3.7559 - val_accuracy: 0.2990\n",
      "Epoch 70/80\n",
      "489/489 [==============================] - 290s 593ms/step - loss: 1.3767 - accuracy: 0.5866 - val_loss: 3.7752 - val_accuracy: 0.2962\n",
      "Epoch 71/80\n",
      "489/489 [==============================] - 292s 598ms/step - loss: 1.3748 - accuracy: 0.5869 - val_loss: 3.7721 - val_accuracy: 0.2998\n",
      "Epoch 72/80\n",
      "489/489 [==============================] - 292s 598ms/step - loss: 1.3739 - accuracy: 0.5863 - val_loss: 3.7977 - val_accuracy: 0.2973\n",
      "Epoch 73/80\n",
      "489/489 [==============================] - 295s 603ms/step - loss: 1.3523 - accuracy: 0.5916 - val_loss: 3.8406 - val_accuracy: 0.2982\n",
      "Epoch 74/80\n",
      "489/489 [==============================] - 291s 596ms/step - loss: 1.3435 - accuracy: 0.5944 - val_loss: 3.8337 - val_accuracy: 0.2960\n",
      "Epoch 75/80\n",
      "489/489 [==============================] - 294s 601ms/step - loss: 1.3443 - accuracy: 0.5942 - val_loss: 3.8477 - val_accuracy: 0.2958\n",
      "Epoch 76/80\n",
      "489/489 [==============================] - 295s 603ms/step - loss: 1.3368 - accuracy: 0.5964 - val_loss: 3.8171 - val_accuracy: 0.2996\n",
      "Epoch 77/80\n",
      "489/489 [==============================] - 297s 607ms/step - loss: 1.3277 - accuracy: 0.6004 - val_loss: 3.8643 - val_accuracy: 0.2996\n",
      "Epoch 78/80\n",
      "489/489 [==============================] - 296s 604ms/step - loss: 1.3160 - accuracy: 0.6013 - val_loss: 3.8511 - val_accuracy: 0.3004\n",
      "Epoch 79/80\n",
      "489/489 [==============================] - 296s 605ms/step - loss: 1.3217 - accuracy: 0.6009 - val_loss: 3.8222 - val_accuracy: 0.3026\n",
      "Epoch 80/80\n",
      "489/489 [==============================] - 297s 608ms/step - loss: 1.3014 - accuracy: 0.6076 - val_loss: 3.8568 - val_accuracy: 0.3028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234a93e0d00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile the model using Adam optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#train the model on training sets and validate on testing sets\n",
    "model.fit(\n",
    "    x_train,y_train,\n",
    "    batch_size=128,epochs=80, \n",
    "    validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MOD\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MOD\\assets\n"
     ]
    }
   ],
   "source": [
    "#save the model for predictions\n",
    "model.save(\"MOD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n",
      "1/1 [==============================] - 1s 533ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model=load_model(\"MOD\")\n",
    "#generate random index\n",
    "index = np.random.randint(0,len(x_test)-1)\n",
    "#get the data of generated index from x_test\n",
    "music_pattern = x_test[index]\n",
    "\n",
    "out_pred=[] #it will store predicted notes\n",
    "\n",
    "#iterate till 200 note is generated\n",
    "for i in range(200):\n",
    "\n",
    "  #reshape the music pattern \n",
    "  music_pattern = music_pattern.reshape(1,len(music_pattern),1)\n",
    "  \n",
    "  #get the maximum probability value from the predicted output\n",
    "  pred_index = np.argmax(model.predict(music_pattern))\n",
    "  #get the note using predicted index and\n",
    "  #append to the output prediction list\n",
    "  out_pred.append(ind2note[pred_index])\n",
    "  music_pattern = np.append(music_pattern,pred_index)\n",
    "  \n",
    "  #update the music pattern with one timestep ahead\n",
    "  music_pattern = music_pattern[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI_composed_music.mid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_notes = []\n",
    "for offset,pattern in enumerate(out_pred):\n",
    "  #if pattern is a chord instance\n",
    "  if ('.' in pattern) or pattern.isdigit():\n",
    "    #split notes from the chord\n",
    "    notes_in_chord = pattern.split('.')\n",
    "    notes = []\n",
    "    for current_note in notes_in_chord:\n",
    "        i_curr_note=int(current_note)\n",
    "        #cast the current note to Note object and\n",
    "        #append the current note \n",
    "        new_note = note.Note(i_curr_note)\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        notes.append(new_note)\n",
    "    \n",
    "    #cast the current note to Chord object\n",
    "    #offset will be 1 step ahead from the previous note\n",
    "    #as it will prevent notes to stack up \n",
    "    new_chord = chord.Chord(notes)\n",
    "    new_chord.offset = offset\n",
    "    output_notes.append(new_chord)\n",
    "  \n",
    "  else:\n",
    "    #cast the pattern to Note object apply the offset and \n",
    "    #append the note\n",
    "    new_note = note.Note(pattern)\n",
    "    new_note.offset = offset\n",
    "    new_note.storedInstrument = instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "\n",
    "#save the midi file \n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='AI_composed_music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py3-TF2.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0cf7052b2cbee69ac1b191b9299109363e1b48785d75e53f65cfba33621fbb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
